{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import lxml.etree as etree\n",
    "import pandas as pd\n",
    "import string\n",
    "from itertools import tee\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def XML_dialogue_concatenater(input_XML_file, output_XML_file, play_counter):\n",
    "\n",
    "    \"\"\"Concatenate dialogues a Moliere's play\n",
    "    \n",
    "    This function concatenate dialogues of a Molière's play (TEI edition,\n",
    "    XML format) into an XML file.\n",
    "    The output XML separates prose from verse dialogues.\n",
    "    Input XML files come from http://dramacode.github.io/moliere/\n",
    "    \n",
    "    Parameter: 'input_XML_file' Molière's play in XML format, TEI edition.\n",
    "               'output_XML_file' file containing the concatenated dialogues.\n",
    "    \n",
    "    Retrun: output_XML_file modified.\n",
    "    \"\"\"\n",
    "\n",
    "    with open(input_XML_file) as f1, open(output_XML_file) as f2:\n",
    "\n",
    "            print('Opening file: ' + input_XML_file)\n",
    "\n",
    "            # Parsing input and output files into Element trees and finding useful tags\n",
    "            input_tree = etree.parse(f1, etree.XMLParser(ns_clean=True, collect_ids=False))\n",
    "            input_root = input_tree.getroot()\n",
    "            body = input_root.find('.//text').find('.//body')\n",
    "\n",
    "            output_tree = etree.parse(f2, etree.XMLParser(ns_clean=True, collect_ids=False))\n",
    "            output_root = output_tree.getroot()\n",
    "            prose = output_root.find('.//prose')\n",
    "            current_prose_play = etree.Element('play' + str(play_counter))\n",
    "            prose.append(current_prose_play)\n",
    "            verse = output_root.find('.//verse')\n",
    "            current_verse_play = etree.Element('play' + str(play_counter))\n",
    "            verse.append(current_verse_play)\n",
    "\n",
    "            # Adding <p> tags into the output file (root > prose)\n",
    "            for element in body.findall('.//p'):\n",
    "                    if ('<p/>') not in str(etree.tostring(element)):\n",
    "                            current_prose_play.append(element)\n",
    "\n",
    "            # Adding <l> tags into the output file (root > verse)\n",
    "            for element in body.findall('.//l'):\n",
    "                    if ('<l/>') not in str(etree.tostring(element)):\n",
    "                            current_verse_play.append(element)\n",
    "\n",
    "            # Deleting all tag attributes of the output tree\n",
    "            for element in output_root.getiterator():\n",
    "                    element.attrib.clear()\n",
    "            \n",
    "            output_tree.write('./XML_format/Precleaned/concatenated_dialogues.xml', pretty_print=True, xml_declaration=True, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenating dialogues of all plays\n",
    "\n",
    "play_counter = 0\n",
    "\n",
    "for filename in os.listdir('./XML_format/Raw/Mixed'):\n",
    "    XML_dialogue_concatenater('./XML_format/Raw/Mixed/' + filename, './XML_format/Precleaned/concatenated_dialogues.xml', play_counter)\n",
    "    play_counter += 1\n",
    "\n",
    "for filename in os.listdir('./XML_format/Raw/Prose'):\n",
    "    if not any(x in filename for x in ['medecinvolant', 'fourberiesdescapin', 'avare']): # Plays that have a specific format (<s> tags)\n",
    "        XML_dialogue_concatenater('./XML_format/Raw/Prose/' + filename, './XML_format/Precleaned/concatenated_dialogues.xml', play_counter)\n",
    "        play_counter += 1\n",
    "\n",
    "for filename in os.listdir('./XML_format/Raw/Verse'):\n",
    "    if not any(x in filename for x in ['sganarelle']): # Corrupted?\n",
    "        XML_dialogue_concatenater('./XML_format/Raw/Verse/' + filename, './XML_format/Precleaned/concatenated_dialogues.xml', play_counter)\n",
    "        play_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a rhyme DataFrame\n",
    "\n",
    "\n",
    "def pairwise(iterable):\n",
    "    a, b = tee(iterable)\n",
    "    next(b, None)\n",
    "    return zip(a, b)\n",
    "\n",
    "\n",
    "with open('./XML_format/Precleaned/concatenated_dialogues.xml') as f:\n",
    "\n",
    "    tree = etree.parse(f, etree.XMLParser(ns_clean=True, collect_ids=False))\n",
    "    root = tree.getroot()\n",
    "    verse = root.find('.//verse')\n",
    "\n",
    "    words10 = []\n",
    "    words20 = []\n",
    "\n",
    "    for e1, e2 in pairwise(verse.findall('.//l')):\n",
    "\n",
    "        if e1.text is not None and e2.text is not None:\n",
    "\n",
    "            # Removing punctuaction, '\\xa0' Unicode and converting to lowercase. Listing each words of sentences.\n",
    "            l1 = list(unicodedata.normalize(\"NFKD\", e1.text.lower().translate(str.maketrans('', '', \"\"\"!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~\"\"\"))).split(' '))\n",
    "            l2 = list(unicodedata.normalize(\"NFKD\", e2.text.lower().translate(str.maketrans('', '', \"\"\"!\"#$%&'()*+,./:;<=>?@[\\]^_`{|}~\"\"\"))).split(' '))\n",
    "\n",
    "            # Removing empty strings\n",
    "            l1 = list(filter(None, l1))\n",
    "            l2 = list(filter(None, l2))\n",
    "\n",
    "            # Creating list of characters of last words\n",
    "            last_word1 = list(l1[-1])\n",
    "            last_word2 = list(l2[-1])\n",
    "\n",
    "            # Creating list of 3 last characters of last words\n",
    "            last_letters1 = last_word1[-3:]\n",
    "            last_letters2 = last_word2[-3:]\n",
    "\n",
    "            # Checking similarities between last 3 letters of last words\n",
    "            similarity_counter = 0\n",
    "            for (letter1, letter2) in zip(last_letters1, last_letters2):\n",
    "                if letter1 == letter2:\n",
    "                    similarity_counter += 1\n",
    "\n",
    "            # Considering a rhyme if at least 2 letters are respectively the same\n",
    "            if similarity_counter >= 2:\n",
    "                words10.append(l1[-1])\n",
    "                words20.append(l2[-1])\n",
    "\n",
    "    \n",
    "\n",
    "    # Deleting self-rhymes (tout, tout), (debout, debout), ...\n",
    "    words11 = []\n",
    "    words21 = []\n",
    "\n",
    "    for i in range(len(words10)):\n",
    "        if words10[i] != words20[i]:\n",
    "            words11.append(words10[i])\n",
    "            words21.append(words20[i])\n",
    "\n",
    "    # Deleting duplucations (tout, debout), (tout, debout), (debout, tout)\n",
    "    rhymes = []\n",
    "\n",
    "    for rhyme in zip(words11, words21):\n",
    "        if (not [rhyme[0], rhyme[1]] in rhymes) and (not [rhyme[1], rhyme[0]] in rhymes):\n",
    "            rhymes.append([rhyme[0], rhyme[1]])\n",
    "    \n",
    "    # Converting into a CSV file\n",
    "    pd.DataFrame(rhymes).to_csv('./Rhymes/rhymes_set_v2.csv', index=False, header=['Word 1', 'Word 2'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "011b5ae7b1f824e9e17532cf660bf76a4e5d222979bbdbc9a307afdbcbfac48c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
